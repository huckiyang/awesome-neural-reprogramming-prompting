# awesome-neural-reprogramming-prompting ![Awesome](https://awesome.re/badge.svg)

A curated list of awesome adversarial reprogramming and input prompting methods for neural networks since 2022.

**News** - Dr. Pin-Yu Chen and Huck will give a tutortial on adversarial reprogramming at ICASSP 2022.  

How to **empower frozen large-scale pre-trained models** with reprogramming and prompting toward different applications is the next big challenge of Deep Learning. Welcome to commit and pull request! 

<img src="https://github.com/huckiyang/awesome-neural-reprogramming-prompting/blob/main/repro-prompt-chh.png" width="300">

## Neural Reprogramming or Adversarial Reprogramming

| Title | Authors | Code | Year |
| ----- | ------- | -------- | ---- |
|[Improved Input Reprogramming for GAN Conditioning](https://arxiv.org/pdf/2201.02692.pdf)|T. Dinh et al.|-|Arxiv 2022|
|[Cross-modal Adversarial Reprogramming](https://openaccess.thecvf.com/content/WACV2022/papers/Neekhara_Cross-Modal_Adversarial_Reprogramming_WACV_2022_paper.pdf)| P. Neekhara et al. |[code](https://github.com/paarthneekhara/multimodal_rerprogramming)|WACV 2022|
|[A Study of Low-Resource Speech Commands Recognition based on Adversarial Reprogramming](https://arxiv.org/pdf/2110.03894.pdf)|H Yen et al.|[code](https://github.com/dodohow1011/SpeechAdvReprogram)|Arxiv 2021|
|[WARP: Word-level Adversarial ReProgramming](https://aclanthology.org/2021.acl-long.381.pdf)|K. Hambardzumyan et al.|[code](https://github.com/YerevaNN/WARP)|ACL 2021|
|[Voice2series: Reprogramming acoustic models for time series classification](https://arxiv.org/pdf/2106.09296.pdf)| CHH Yang, et al.|[code](https://github.com/huckiyang/Voice2Series-Reprogramming)|ICML 2021|
|[Transfer learning without knowing: Reprogramming black-box machine learning models with scarce data and limited resources](http://proceedings.mlr.press/v119/tsai20a/tsai20a.pdf)|Y Tsai et al.|[code](https://github.com/yunyuntsai/Black-box-Adversarial-Reprogramming)|ICML 2020|
|[Reprogramming GANs via Input Noise Design](http://csuh.kaist.ac.kr/Suh_Reprogramming_GAN.pdf)|K Lee et al.|-|ECML 2019|
|[Adversarial Reprogramming of Text Classification Neural Networks](https://arxiv.org/abs/1809.01829)| P. Neekhara et al. |[code](https://github.com/paarthneekhara/rnn_adversarial_reprogramming)|EMNLP 2019|
|[Adversarial reprogramming of neural networks](https://arxiv.org/pdf/1806.11146.pdf)|F. Elsayed et al.|[code](https://github.com/Prinsphield/Adversarial_Reprogramming)|ICLR 2019|

## Input-Level Neural Model Prompting

| Title | Authors | Code | Year |
| ----- | ------- | -------- | ---- |
|[WAVPROMPT: Towards Few-Shot Spoken Language Understanding with Frozen Language Models](https://arxiv.org/pdf/2203.15863.pdf)|H. Gao et al.|-|Arxiv 2022|
|[An Exploration of Prompt Tuning on Generative Spoken Language Model for Speech Processing Tasks](https://arxiv.org/pdf/2203.16773.pdf)| K.-W. Chang et al. |-|Arxiv 2022|
|[Visual Prompting: Modifying Pixel Space to Adapt Pre-trained Models](https://arxiv.org/pdf/2203.17274.pdf)|H. Bahng et al.|-|Arxiv 2022|
